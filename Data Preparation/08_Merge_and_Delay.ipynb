{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08: Merge \"Stop Times with Buffer zones\" with realtime data and compute delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will merge the stop times with buffer zones from notebook 4 with the realtime data from notebook 7. Then, we will compute the delay between the actual PT times and the planned ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from datetime import datetime\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import shapely\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set month\n",
    "data_month_single = '7'\n",
    "data_month_double = '07'\n",
    "data_month_int = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load PT plan data\n",
    "plan = pd.read_parquet('../Data/04_merged_stop_times_buffer_zones.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform geometry\n",
    "point = gpd.GeoDataFrame(geometry=gpd.GeoSeries.from_wkb(plan[\"station_point\"], crs=4326))\n",
    "buffer = gpd.GeoDataFrame(geometry=gpd.GeoSeries.from_wkb(plan[\"buffer_zone\"], crs=4326))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop geometry columns in wrong format\n",
    "plan = plan.drop(columns=[\"station_point\", \"buffer_zone\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace geometry columns with correct format\n",
    "plan['station_point'] = point\n",
    "plan['buffer_zone'] = buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop lat and long columns\n",
    "plan.drop(columns=['lat', 'long'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_m/71fq0nk106s02qxvct5s2sv80000gn/T/ipykernel_7443/2188162843.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  actual = pd.read_csv('/Volumes/T7/Master/Processed Data/'+ data_month_double + '/08_vrs_merged_with_trips.csv')\n"
     ]
    }
   ],
   "source": [
    "# load realtime data\n",
    "actual = pd.read_csv('../Data/07_vrs_merged_with_trips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop schedule_relationship column, since all values are 0\n",
    "actual.drop(columns=['schedule_relationship'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25212760 entries, 0 to 25212759\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Dtype \n",
      "---  ------               ----- \n",
      " 0   route_id             int64 \n",
      " 1   agency_id            int64 \n",
      " 2   route_short_name     object\n",
      " 3   route_type           int64 \n",
      " 4   route_type_name      object\n",
      " 5   agency_name          object\n",
      " 6   service_id           int64 \n",
      " 7   trip_id              object\n",
      " 8   trip_headsign        object\n",
      " 9   direction_id         int64 \n",
      " 10  shape_id             int64 \n",
      " 11  start_date           int64 \n",
      " 12  stop_id              int64 \n",
      " 13  stop_arrival_time    object\n",
      " 14  stop_departure_time  object\n",
      " 15  vrs_timestamp        int64 \n",
      "dtypes: int64(9), object(7)\n",
      "memory usage: 3.0+ GB\n"
     ]
    }
   ],
   "source": [
    "actual.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "actual.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25202520 entries, 0 to 25212759\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Dtype \n",
      "---  ------               ----- \n",
      " 0   route_id             int64 \n",
      " 1   agency_id            int64 \n",
      " 2   route_short_name     object\n",
      " 3   route_type           int64 \n",
      " 4   route_type_name      object\n",
      " 5   agency_name          object\n",
      " 6   service_id           int64 \n",
      " 7   trip_id              object\n",
      " 8   trip_headsign        object\n",
      " 9   direction_id         int64 \n",
      " 10  shape_id             int64 \n",
      " 11  start_date           int64 \n",
      " 12  stop_id              int64 \n",
      " 13  stop_arrival_time    object\n",
      " 14  stop_departure_time  object\n",
      " 15  vrs_timestamp        int64 \n",
      "dtypes: int64(9), object(7)\n",
      "memory usage: 3.2+ GB\n"
     ]
    }
   ],
   "source": [
    "actual.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 18, '18', 'SB55', 'SB60', '61', 61, 62, 63, 65, 66, 67, '67',\n",
       "       '68', 'SB69', '540', 540, 600, 601, 602, 603, 604, 605, 606, 607,\n",
       "       608, 609, 610, 611, 612, 613, 614, 630, 631, 632, 633, 634, 635,\n",
       "       636, 637, 638, 640, '640', 'E', 'N1', 'N2', 'N3', 'N4', 'N5', 'N6',\n",
       "       'N7', 'N8', 'N9', 'N10', '842', 842, 884, 516, 529, 537, 541, 550,\n",
       "       551, 552, 599, 800, 812, 817, 818, 843, 845, 855, 856, 857],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual['route_short_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge realtime and plan data\n",
    "#merged_df = actual.merge(plan, on=['stop_id', 'trip_id'])\n",
    "merged_df = pd.merge(actual, plan, on=['stop_id', 'trip_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 18, '18', 'SB55', 'SB60', '61', 61, 62, 63, 65, 66, 67, '67',\n",
       "       '68', 'SB69', '540', 540, 600, 601, 602, 603, 604, 605, 606, 607,\n",
       "       608, 609, 610, 611, 612, 613, 614, 630, 631, 632, 633, 634, 635,\n",
       "       636, 637, 638, 640, '640', 'E', 'N1', 'N2', 'N3', 'N4', 'N5', 'N6',\n",
       "       'N7', 'N8', 'N9', 'N10', '842', 842, 884, 516, 529, 537, 541, 550,\n",
       "       551, 552, 599, 800, 812, 817, 818, 843, 845, 855, 856, 857],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['route_short_name'].unique()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform start_date to date\n",
    "merged_df['start_date'] = pd.to_datetime(merged_df['start_date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datetime columns\n",
    "merged_df['start_datetime'] = pd.to_datetime(merged_df['start_date']) + pd.to_timedelta(merged_df['arrival_time'])\n",
    "merged_df['end_datetime'] = pd.to_datetime(merged_df['start_date']) + pd.to_timedelta(merged_df['departure_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_gdf = gpd.GeoDataFrame(merged_df, geometry='station_point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to parquet\n",
    "#temporary_gdf.to_parquet('/Volumes/T7/Master/Processed Data/'+data_month_double+'/08_temporary.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "merged_df.rename(columns={'start_datetime': 'scheduled_arrival_time', 'end_datetime': 'scheduled_departure_time'}, inplace=True)\n",
    "merged_df.rename(columns={'stop_arrival_time': 'actual_arrival_time', 'stop_departure_time': 'actual_departure_time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "merged_df.drop(columns=['arrival_time', 'departure_time', 'start_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 0 values with None for datetime conversion\n",
    "merged_df['actual_arrival_time'] = merged_df['actual_arrival_time'].replace('0', None)\n",
    "merged_df['actual_departure_time'] = merged_df['actual_departure_time'].replace('0', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into datetime\n",
    "merged_df['actual_arrival_time'] = pd.to_datetime(merged_df['actual_arrival_time'])\n",
    "merged_df['actual_departure_time'] = pd.to_datetime(merged_df['actual_departure_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute delays\n",
    "merged_df['arrival_delay'] = merged_df['actual_arrival_time'] - merged_df['scheduled_arrival_time']\n",
    "merged_df['departure_delay'] = merged_df['actual_departure_time'] - merged_df['scheduled_departure_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are cases, where the actual arrival time is before the scheduled arrival time, meaning that the PT vehicle arrived too early. Set these cases to 0\n",
    "merged_df['arrival_delay'] = merged_df['arrival_delay'].apply(lambda x: pd.Timedelta(0) if x < pd.Timedelta(0) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are cases, where the actual departure time is before the scheduled departure time, meaning that the PT vehicle departed too early. This is not good, but not of interested since it is no delay. Set these cases to 0.\n",
    "merged_df['departure_delay'] = merged_df['departure_delay'].apply(lambda x: pd.Timedelta(0) if x < pd.Timedelta(0) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(merged_df, geometry='station_point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert route_short_name to string\n",
    "gdf['route_short_name'] = gdf['route_short_name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDer Kernel ist beim Ausführen von Code in der aktuellen Zelle oder einer vorherigen Zelle abgestürzt. \n",
      "\u001b[1;31mBitte überprüfen Sie den Code in der/den Zelle(n), um eine mögliche Fehlerursache zu identifizieren. \n",
      "\u001b[1;31mKlicken Sie <a href='https://aka.ms/vscodeJupyterKernelCrash'>hier</a>, um weitere Informationen zu erhalten. \n",
      "\u001b[1;31mWeitere Informationen finden Sie unter Jupyter <a href='command:jupyter.viewOutput'>Protokoll</a>."
     ]
    }
   ],
   "source": [
    "gdf.to_csv('../Data/08_realtime_buffer_delay.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to parquet\n",
    "gdf.to_parquet('../Data/08_first_merge_NEU.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Andrej",
   "language": "python",
   "name": "andrej"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
